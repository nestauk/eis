{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web sources\n",
    "\n",
    "This is a sandbox to explore potential web indicator data collections for EIS.\n",
    "\n",
    "We will:\n",
    "\n",
    "* Create a summary table\n",
    "* Collect LinkedIn skills migration data\n",
    "* Explore options to query Google Big query about:\n",
    "  * GitHub\n",
    "  * Python downloads\n",
    "* Carry out a toy scrape of the Study portals website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy\n",
    "\n",
    "from eis.utils.data_processing import *\n",
    "from datetime import datetime\n",
    "import seaborn as sn\n",
    "from ast import literal_eval\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('font', size=14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various credentials to collect Nesta and Google Big Query data\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "cp = os.environ.get('config_path')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = pd.read_csv(\n",
    "    'https://www.eea.europa.eu/data-and-maps/data/waterbase-lakes-4/country-codes-and-abbreviations-32-records/country-codes-and-abbreviations-32-records/at_download/file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "ind = pd.read_csv(f\"{project_dir}/data/aux/eis_indicator_inventory.csv\",na_values='TBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.loc[ind['method_type']=='Web'][\n",
    "    ['category','indicator','source','description']].to_csv(f\"{material_outputs}/table_4_web.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = pd.read_excel('https://development-data-hub-s3-public.s3.amazonaws.com/ddhfiles/144635/public_use-talent-migration.xlsx',\n",
    "                  sheet_name='Skill Migration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_codes = set([x.lower() for x in country_codes['ISO2']])\n",
    "eu_li = li.loc[[x in eu_codes for x in li['country_code']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = ['Artificial Intelligence','Data Science','Natural Language Processing']\n",
    "eu_ai = eu_li.loc[[x in ai for x in eu_li['skill_group_name']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = ['country_name','country_code','net_per_10K_2015','net_per_10K_2016','net_per_10K_2017','net_per_10K_2018']\n",
    "\n",
    "eu_ai_long = eu_ai[rel].melt(id_vars=['country_name','country_code'])\n",
    "\n",
    "eu_ai_long['year'] = [int(x.split('_')[-1]) for x in eu_ai_long['variable']]\n",
    "\n",
    "ai_agg = eu_ai_long.pivot_table(\n",
    "    index='country_code',columns='year',values='value',aggfunc='sum').sort_values(2018,ascending=True)\n",
    "\n",
    "ai_agg = ai_agg.T.rolling(window=2).mean().dropna().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_agg_long = ai_agg.reset_index(drop=False).melt(id_vars=['country_code'],\n",
    "                                                  var_name='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(ai_agg_long)\n",
    "\n",
    "a = base.mark_point().encode(y=alt.Y('country_code',axis=alt.Axis(grid=True,gridWidth=3),\n",
    "                                    sort=alt.EncodingSortField('value','mean',order='descending')),\n",
    "                                     x=alt.X('value',title='net flow of talent per 10K members'),\n",
    "                             color='year:N',shape='year:N')\n",
    "b = base.mark_line(strokeDash=[3,1],strokeWidth=3).encode(\n",
    "    y=alt.Y('country_code:N',sort=alt.EncodingSortField('value','mean',order='descending')),\n",
    "    x='value:Q',detail=alt.Detail('country_code:N'))\n",
    "\n",
    "c = base.mark_rule().transform_calculate(zero='0').encode(x='zero:Q')\n",
    "\n",
    "d = (a+b+c).properties(height=500)\n",
    "\n",
    "save(d,f\"{material_outputs}_v1/fig_11_linkedin.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_getters.meetup import select_meetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eu_meetup_groups = []\n",
    "\n",
    "# for x in [x for x in country_codes['ISO2']]:\n",
    "    \n",
    "#     print(x)\n",
    "#     res = select_meetup(cp, 34, x)\n",
    "    \n",
    "#     eu_meetup_groups.append(res)\n",
    "\n",
    "# with open(f\"{project_dir}/data/raw/eu_meetup.p\",'wb') as outfile:\n",
    "#     pickle.dump(eu_meetup_groups,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{project_dir}/data/raw/eu_meetup.p\",'rb') as infile:\n",
    "    eu_meetup_groups = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = pd.concat([x['core_groups'] for x in eu_meetup_groups]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gs)\n",
    "np.sum(gs['country']=='AL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.members.sum()/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some parsing\n",
    "\n",
    "#of years\n",
    "gs['year'] = [datetime.fromtimestamp(np.float(x)/1000).year for x in gs['created']]\n",
    "\n",
    "#Of topics\n",
    "gs['topic_list'] = [literal_eval(x) for x in gs['topics']]\n",
    "gs['topic_kws'] = [[x['urlkey'] for x in el] for el in gs['topic_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(flatten_list(gs['topic_kws'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag meetups with AI keywords\n",
    "ai = set(['machine-learning','ai','deep-learning','data-science'])\n",
    "vr = set(['virtual-reality','augmented-reality','vr'])\n",
    "crypto = set(['cryptocurrency','blockchain','bitcoin'])\n",
    "\n",
    "gs['has_ai'],gs['has_vr'],gs['has_crypto'] = [\n",
    "    [int(len(tech_set & set(kws))>0) for kws in gs['topic_kws']] for tech_set in [ai,vr,crypto]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetup_long = pd.crosstab(gs['country'],gs['year']).cumsum(axis=1).reset_index(drop=False).melt(id_vars='country',value_name='groups')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_1 = alt.Chart(meetup_long,width=60,height=70).mark_line().encode(x='year:O',\n",
    "                                                 y='groups',\n",
    "                                         facet=alt.Facet('country',columns=8,\n",
    "                                                        sort=alt.EncodingSortField('groups','max',\n",
    "                                                                          order='descending')))\n",
    "\n",
    "\n",
    "ch_1.save(f'{material_outputs}_v1/fig_12_meetup.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(figsize=(12,7),nrows=2,sharex=True)\n",
    "\n",
    "# country_freqs =  gs['country'].value_counts()\n",
    "# country_freqs.plot.bar(cmap='Purples_r',ax=ax[0])\n",
    "\n",
    "# (100*gs.groupby('country')['has_ai'].mean()).loc[country_freqs.index].plot.bar(ax=ax[1],cmap='Purples',\n",
    "#                                                                         edgecolor='purple')\n",
    "\n",
    "# ax[0].set_ylabel('Total number of meetups')\n",
    "# ax[1].set_ylabel('% of meetups in AI')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# save_fig('fig_8_meetups.pdf',material_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_tech_ev = (100*gs.groupby(['year'])[['has_ai','has_vr','has_crypto']\n",
    "                    ].mean()).reset_index(drop=False).melt(id_vars='year',var_name='Technology activity')\n",
    "\n",
    "em_tech_geo = gs.groupby(['country'])[['has_ai','has_vr','has_crypto']\n",
    "                    ].sum().apply(lambda x: 100*x/x.sum()).reset_index(drop=False).melt(id_vars='country',\n",
    "                                                                                   var_name='Technology',\n",
    "                                                                                       value_name='Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_3 = alt.Chart(em_tech_ev,width=600).transform_window(\n",
    "    mean_value='mean(value)',groupby=['Technology activity'],frame=[-1,+1]).mark_line().encode(\n",
    "x=alt.X('year:O'),y=alt.Y('mean_value:Q',title='% of activity accounted by year'),color='Technology activity')\n",
    "\n",
    "\n",
    "ch_4 = alt.Chart(em_tech_geo).mark_circle(stroke='black',\n",
    "                                         strokeWidth=1).encode(y=alt.Y('Technology:N',sort=['has_ai','has_crypto','has_vr']),\n",
    "                                         x = alt.X('country',sort=alt.EncodingSortField(\n",
    "                                             'Share','sum',order='descending')),\n",
    "                                                               size=alt.Size('Share',legend=None),\n",
    "                                                               color='Share').properties(height=100)\n",
    "\n",
    "ch_5 = alt.vconcat(ch_3,ch_4)\n",
    "\n",
    "ch_5\n",
    "\n",
    "save(ch_5,f\"{material_outputs}_v1/fig_14_meetup.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google big queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    f\"{project_dir}/gbq_eis_credentials.json\")\n",
    "\n",
    "project_id = 'eis-2-275207'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This query extracts a count of unique year by year of registration and country code\n",
    "#Removing fake accounts\n",
    "q1 = '''SELECT EXTRACT (YEAR FROM created_at), COUNT(id), country_code\n",
    "FROM `ghtorrentmysql1906.MySQL1906.users`\n",
    "WHERE fake = 0 AND deleted = 0\n",
    "GROUP BY country_code, EXTRACT (YEAR FROM created_at)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_reg = pandas_gbq.read_gbq(q1, \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_reg.rename(columns={'f0_':'year_created','f1_':'user_count','country_code':'country_code'},\n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_wide = github_reg.pivot_table(index='year_created',columns='country_code',\n",
    "                                    values='user_count').fillna(0)\n",
    "top_github_eu = github_wide[eu_codes].sum().sort_values(ascending=False)\n",
    "\n",
    "top_gh_eu_names = top_github_eu[:7].index\n",
    "\n",
    "eu_totals = pd.concat([github_wide[top_gh_eu_names],\n",
    "           github_wide[[x for x in github_wide.columns if (x in eu_codes) & (x not in top_gh_eu_names)\n",
    "                       ]].sum(\n",
    "               axis=1).rename('other')],\n",
    "         axis=1).cumsum().T\n",
    "\n",
    "#Need this to order the variables\n",
    "eu_totals['order'] = list(range(0,8))\n",
    "eu_totals_long = eu_totals.reset_index(drop=False).melt(id_vars=['index','order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_g = alt.Chart(eu_totals_long).mark_area().encode(x='year_created:O',\n",
    "                                             y=alt.Y('value',title='Registered members (cumulative)'),\n",
    "                                             color=alt.Color('index',\n",
    "                                                             sort=list(eu_totals.index)[::-1]),\n",
    "                                            order='order').properties(width=400)\n",
    "\n",
    "save(ch_g,f'{material_outputs}_v1/fig_15_github.pdf')\n",
    "\n",
    "ch_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_count_df = top_github_eu.reset_index(drop=False).rename(columns={0:'Registered users'})\n",
    "\n",
    "ch_g_us = alt.Chart(github_count_df,height=200).mark_bar().encode(x=alt.X('country_code',sort=alt.EncodingSortField('count',\n",
    "                                                    order='descending')),\n",
    "                                             y='Registered users')\n",
    "save(ch_g_us,f\"{material_outputs}_v1/fig_16_github_count.pdf\")\n",
    "\n",
    "ch_g_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_github_eu.sum()/github_wide.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyq_all = '''SELECT COUNT(*), country_code\n",
    "FROM `the-psf.pypi.file_downloads` \n",
    "WHERE DATE(timestamp) = \"{}\" \n",
    "GROUP BY country_code'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyq_ml = '''SELECT COUNT(*), country_code\n",
    "FROM `the-psf.pypi.file_downloads` \n",
    "WHERE file.project in ('tensorflow','keras','pytorch','sklearn') AND DATE(timestamp) = \"{}\" \n",
    "GROUP BY country_code'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_all = [pandas_gbq.read_gbq(pyq_all.format(f'2020-04-0{str(n)}'), \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds) for n in np.arange(1,7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_ml = [pandas_gbq.read_gbq(pyq_ml.format(f'2020-04-0{str(n)}'), \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds) for n in np.arange(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads = pd.concat([\n",
    "    pd.concat(df).groupby('country_code')['f0_'].mean().rename(name) for df,name in \n",
    "    zip([py_all,py_ml],['all_files','ml_packages'])],axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads.index = [x.lower() for x in py_downloads.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro_py = py_downloads.loc[eu_codes].sort_values('all_files',ascending=False)\n",
    "\n",
    "euro_py_long = (100*euro_py.apply(lambda x: x/x.sum())).reset_index(drop=False).melt(id_vars='index',\n",
    "                                                                      var_name='download_type',value_name=\n",
    "                                                                                     'download_share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(euro_py_long)\n",
    "\n",
    "x_pos = alt.X('index',sort=alt.EncodingSortField(field='download_share',op='sum',order='descending'))\n",
    "y_pos = alt.Y('download_share',title='Share of EU downloads')\n",
    "\n",
    "p = base.mark_point(filled=True,size=50,stroke='black',strokeWidth=1).encode(x=x_pos,y=y_pos,color='download_type',\n",
    "                             shape='download_type')\n",
    "\n",
    "l = base.mark_line(strokeDash=[1,2]).encode(x=x_pos,y=y_pos,detail='index')\n",
    "\n",
    "f = (p+l).properties(width=500,height=200)\n",
    "\n",
    "save(f,f\"{material_outputs}_v1/fig_17_python_dloads.pdf\")\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads.assign(\n",
    "    is_eu = lambda x: [x in eu_codes for x in py_downloads.index]).groupby('is_eu').sum(\n",
    ").T.assign(share = lambda x: x[True]/x.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads.assign(\n",
    "    is_cn = lambda x: [x == 'cn' for x in x.index]).groupby('is_cn').sum(\n",
    ").T.assign(share = lambda x: x[True]/x.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second one extracts count of activity in a location by year\n",
    "q2 = '''SELECT EXTRACT (YEAR FROM creation_date), COUNT(id), location\n",
    "FROM `bigquery-public-data.stackoverflow.users` \n",
    "GROUP BY location, EXTRACT (YEAR FROM creation_date) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackover = pandas_gbq.read_gbq(q2, \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stack_locs = stackover.groupby('location')['f1_'].sum().sort_values(\n",
    "    ascending=False)[:20].reset_index(drop=False).rename(columns={'f1_':'users'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = alt.Chart(top_stack_locs).mark_bar().encode(y=\n",
    "                                            alt.Y('location:O',sort=alt.EncodingSortField('users',order='descending')),\n",
    "                                                  x='users:Q').properties(width=200,height=250)\n",
    "\n",
    "save(stack,f\"{material_outputs}_v1/fig_18_stack_users.pdf\")\n",
    "\n",
    "stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all the data for the analytical synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetup_long = pd.crosstab(\n",
    "    gs['country'],gs['year']).reset_index(drop=False).melt(id_vars=['country'],\n",
    "                                                           value_name='tech_meetups')\n",
    "github_long = github_wide.reset_index(drop=False).melt(\n",
    "    id_vars='year_created',value_name='github_users').rename(\n",
    "    columns={'year_created':'year','country_code':'country'})\n",
    "\n",
    "python_long = py_downloads['all_files'].loc[eu_codes].reset_index(drop=False).rename(columns={\n",
    "    'index':'country','all_files':'python_downloads'}).assign(year=2018)\n",
    "\n",
    "out = pd.concat([x.melt(id_vars=['country','year']) for x in [meetup_long,github_long,python_long]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(f\"{project_dir}/data/processed/web_indicators.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
