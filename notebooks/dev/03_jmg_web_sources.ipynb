{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web sources\n",
    "\n",
    "This is a sandbox to explore potential web indicator data collections for EIS.\n",
    "\n",
    "We will:\n",
    "\n",
    "* Create a summary table\n",
    "* Collect LinkedIn skills migration data\n",
    "* Explore options to query Google Big query about:\n",
    "  * GitHub\n",
    "  * Python downloads\n",
    "* Carry out a toy scrape of the Study portals website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy\n",
    "\n",
    "from eis.utils.data_processing import *\n",
    "from datetime import datetime\n",
    "import seaborn as sn\n",
    "from ast import literal_eval\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('font', size=14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various credentials to collect Nesta and Google Big Query data\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "cp = os.environ.get('config_path')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = pd.read_csv(\n",
    "    'https://www.eea.europa.eu/data-and-maps/data/waterbase-lakes-4/country-codes-and-abbreviations-32-records/country-codes-and-abbreviations-32-records/at_download/file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "ind = pd.read_csv(f\"{project_dir}/data/aux/eis_indicator_inventory.csv\",na_values='TBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.loc[ind['method_type']=='Web'][\n",
    "    ['category','indicator','source','description']].to_csv(f\"{material_outputs}/table_4_web.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = pd.read_excel('https://development-data-hub-s3-public.s3.amazonaws.com/ddhfiles/144635/public_use-talent-migration.xlsx',\n",
    "                  sheet_name='Skill Migration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_codes = set([x.lower() for x in country_codes['ISO2']])\n",
    "eu_li = li.loc[[x in eu_codes for x in li['country_code']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = ['Artificial Intelligence','Data Science','Natural Language Processing']\n",
    "eu_ai = eu_li.loc[[x in ai for x in eu_li['skill_group_name']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = ['country_name','country_code','net_per_10K_2015','net_per_10K_2016','net_per_10K_2017','net_per_10K_2018']\n",
    "\n",
    "eu_ai_long = eu_ai[rel].melt(id_vars=['country_name','country_code'])\n",
    "\n",
    "eu_ai_long['year'] = [int(x.split('_')[-1]) for x in eu_ai_long['variable']]\n",
    "\n",
    "ai_agg = eu_ai_long.pivot_table(\n",
    "    index='country_code',columns='year',values='value',aggfunc='sum').sort_values(2018,ascending=True)\n",
    "\n",
    "ai_agg = ai_agg.T.rolling(window=2).mean().dropna().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ai_agg.plot.barh(figsize=(5,10))\n",
    "ax.set_xlabel('Net gain or loss of talent with skill \\n (2-year rolling average)')\n",
    "\n",
    "save_fig(\"fig_7_linkedin.pdf\",material_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_getters.meetup import select_meetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_meetup_groups = []\n",
    "\n",
    "for x in [x for x in country_codes['ISO2']]:\n",
    "    \n",
    "    print(x)\n",
    "    res = select_meetup(cp, 34, x)\n",
    "    \n",
    "    eu_meetup_groups.append(res)\n",
    "\n",
    "# with open(f\"{project_dir}/data/raw/eu_meetup_groups.p\",'w') as outfile:\n",
    "#     pickle.dumps(eu_meetup_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{project_dir}/data/raw/eu_meetups.p\",'wb') as outfile:\n",
    "    pickle.dump(eu_meetup_groups,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = pd.concat([x['core_groups'] for x in eu_meetup_groups]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gs)\n",
    "np.sum(gs['country']=='AL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.members.sum()/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some parsing\n",
    "\n",
    "#of years\n",
    "gs['year'] = [datetime.fromtimestamp(np.float(x)/1000).year for x in gs['created']]\n",
    "\n",
    "#Of topics\n",
    "gs['topic_list'] = [literal_eval(x) for x in gs['topics']]\n",
    "gs['topic_kws'] = [[x['urlkey'] for x in el] for el in gs['topic_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(flatten_list(gs['topic_kws'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag meetups with AI keywords\n",
    "ai = set(['machine-learning','ai','deep-learning','data-science'])\n",
    "vr = set(['virtual-reality','augmented-reality','vr'])\n",
    "crypto = set(['cryptocurrency','blockchain','bitcoin'])\n",
    "\n",
    "gs['has_ai'],gs['has_vr'],gs['has_crypto'] = [\n",
    "    [len(tech_set & set(kws))>0 for kws in gs['topic_kws']] for tech_set in [ai,vr,crypto]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,7),nrows=2,sharex=True)\n",
    "\n",
    "country_freqs =  gs['country'].value_counts()\n",
    "country_freqs.plot.bar(cmap='Purples_r',ax=ax[0])\n",
    "\n",
    "(100*gs.groupby('country')['has_ai'].mean()).loc[country_freqs.index].plot.bar(ax=ax[1],cmap='Purples',\n",
    "                                                                        edgecolor='purple')\n",
    "\n",
    "ax[0].set_ylabel('Total number of meetups')\n",
    "ax[1].set_ylabel('% of meetups in AI')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_fig('fig_8_meetups.pdf',material_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (100*gs.groupby(['year'])[['has_ai','has_vr','has_crypto']\n",
    "                    ].mean().rolling(window=3).mean().dropna()).plot(color=['purple','blue','orange'])\n",
    "\n",
    "ax.set_ylabel('Share of technology meetups \\n with topic')\n",
    "\n",
    "save_fig('fig_9_meetup_topics.pdf',material_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google big queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    f\"{project_dir}/gbq_eis_credentials.json\")\n",
    "\n",
    "project_id = 'eis-2-275207'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This query extracts a count of unique year by year of registration and country code\n",
    "#Removing fake accounts\n",
    "q1 = '''SELECT EXTRACT (YEAR FROM created_at), COUNT(id), country_code\n",
    "FROM `ghtorrentmysql1906.MySQL1906.users`\n",
    "WHERE fake = 0 AND deleted = 0\n",
    "GROUP BY country_code, EXTRACT (YEAR FROM created_at)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_reg = pandas_gbq.read_gbq(q1, \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_reg.rename(columns={'f0_':'year_created','f1_':'user_count','country_code':'country_code'},\n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_wide = github_reg.pivot_table(index='year_created',columns='country_code',\n",
    "                                    values='user_count').fillna(0)\n",
    "top_github_eu = github_wide[eu_codes].sum().sort_values(ascending=False)\n",
    "\n",
    "top_gh_eu_names = top_github_eu[:7].index\n",
    "\n",
    "eu_totals = pd.concat([github_wide[top_gh_eu_names],\n",
    "           github_wide[[x for x in github_wide.columns if (x in eu_codes) & (x not in top_gh_eu_names)\n",
    "                       ]].sum(\n",
    "               axis=1).rename('other')],\n",
    "         axis=1)\n",
    "\n",
    "ax = eu_totals.cumsum().plot.area(cmap='Accent',figsize=(7,4))\n",
    "ax.ticklabel_format(axis='y',style='sci')\n",
    "ax.set_ylabel('Registered users \\n (cumulative)')\n",
    "ax.set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig('fig_10_github_trends.pdf',material_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = top_github_eu.plot.bar(color='Purple',figsize=(10,4))\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Total number of \\n registered users')\n",
    "save_fig('fig_11_github_countries.pdf',material_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_github_eu.sum()/github_wide.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyq_all = '''SELECT COUNT(*), country_code\n",
    "FROM `the-psf.pypi.file_downloads` \n",
    "WHERE DATE(timestamp) = \"{}\" \n",
    "GROUP BY country_code'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyq_ml = '''SELECT COUNT(*), country_code\n",
    "FROM `the-psf.pypi.file_downloads` \n",
    "WHERE file.project in ('tensorflow','keras','pytorch','sklearn') AND DATE(timestamp) = \"{}\" \n",
    "GROUP BY country_code'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_all = [pandas_gbq.read_gbq(pyq_all.format(f'2019-09-0{str(n)}'), \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds) for n in np.arange(1,7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_ml = [pandas_gbq.read_gbq(pyq_ml.format(f'2019-09-0{str(n)}'), \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds) for n in np.arange(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads = pd.concat([\n",
    "    pd.concat(df).groupby('country_code')['f0_'].mean().rename(name) for df,name in \n",
    "    zip([py_all,py_ml],['all_files','ml_packages'])],axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads.index = [x.lower() for x in py_downloads.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro_py = py_downloads.loc[eu_codes].sort_values('all_files',ascending=False)\n",
    "\n",
    "ax = (100*euro_py.apply(lambda x: x/x.sum())).plot.bar(\n",
    "    cmap='Purples_r',edgecolor='purple',figsize=(12,5))\n",
    "ax.set_ylabel('% of downloads \\n accounted by the country')\n",
    "\n",
    "save_fig('fig_12_python_dowloads.pdf',material_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads.assign(\n",
    "    is_eu = lambda x: [x in eu_codes for x in py_downloads.index]).groupby('is_eu').sum(\n",
    ").T.assign(share = lambda x: x[True]/x.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_downloads.assign(\n",
    "    is_cn = lambda x: [x == 'cn' for x in x.index]).groupby('is_cn').sum(\n",
    ").T.assign(share = lambda x: x[True]/x.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second one extracts count of activity in a location by year\n",
    "q2 = '''SELECT EXTRACT (YEAR FROM creation_date), COUNT(id), location\n",
    "FROM `bigquery-public-data.stackoverflow.users` \n",
    "GROUP BY location, EXTRACT (YEAR FROM creation_date) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackover = pandas_gbq.read_gbq(q2, \n",
    "                project_id='eis-2-275207',\n",
    "                credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = stackover.groupby('location')['f1_'].sum().sort_values(ascending=False)[:20][::-1].plot.barh(\n",
    "figsize=(7,7),color='Purple')\n",
    "ax.set_xlabel('Registered users')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "save_fig('fig_13_stack_overflow.pdf',material_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all the data for the analytical synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetup_long = pd.crosstab(\n",
    "    gs['country'],gs['year']).reset_index(drop=False).melt(id_vars=['country'],\n",
    "                                                           value_name='tech_meetups')\n",
    "github_long = github_wide.reset_index(drop=False).melt(\n",
    "    id_vars='year_created',value_name='github_users').rename(\n",
    "    columns={'year_created':'year','country_code':'country'})\n",
    "\n",
    "python_long = py_downloads['all_files'].loc[eu_codes].reset_index(drop=False).rename(columns={\n",
    "    'index':'country','all_files':'python_downloads'}).assign(year=2019)\n",
    "\n",
    "out = pd.concat([x.melt(id_vars=['country','year']) for x in [meetup_long,github_long,python_long]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(f\"{project_dir}/data/interim/web_indicators.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
