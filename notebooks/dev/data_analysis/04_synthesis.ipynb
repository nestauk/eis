{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas_datareader\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "from eis.utils.data_processing import *\n",
    "from selenium import webdriver\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altair saving code\n",
    "w = make_altair_save()\n",
    "\n",
    "save_dir = f\"{project_dir}/reports/figures/final_report\"\n",
    "\n",
    "def save_altair_(f,n):\n",
    "    save_altair(f,n,w,fig_path=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_path}/aux/eu_codes_names.txt\",'r') as infile:\n",
    "    eu_27_other_codes = infile.read().split(', ')\n",
    "    \n",
    "eu_codes_lookup = {x.split(':')[0].strip().lower(): x.split(':')[1].strip() for x in eu_27_other_codes}\n",
    "eu_codes_lookup['gr']= 'Greece'\n",
    "eu_codes_lookup['gb'] = 'United Kingdom'\n",
    "eu_codes_lookup['uk'] = 'United Kingdom'\n",
    "eu_codes_lookup['is'] = 'Iceland'\n",
    "eu_codes_lookup['il'] = 'Israel'\n",
    "eu_codes_lookup['ua'] = 'Ukraine'\n",
    "\n",
    "eu_codes = set(eu_codes_lookup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_codes = pd.read_csv(\n",
    "#     'https://www.eea.europa.eu/data-and-maps/data/waterbase-lakes-4/country-codes-and-abbreviations-32-records/country-codes-and-abbreviations-32-records/at_download/file')\n",
    "\n",
    "# eu_codes = set([x.lower() for x in country_codes['ISO2']]+['uk',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"{project_dir}/data/aux/eu_country_codes.txt\",'r') as infile:\n",
    "#     eu_codes_2 = infile.read().split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{project_dir}/data/aux/all_clean_names.json\",'r') as infile:\n",
    "    \n",
    "    clean_names= json.load(infile)\n",
    "    \n",
    "with open(f\"{project_dir}/data/aux/eurostat_clean_names.json\",'r') as infile:\n",
    "    \n",
    "    es_clean_names= json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = {**clean_names,**es_clean_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lookup to change a couple of country codes\n",
    "country_name_changes = {'gb':'uk','gr':'el'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eu_code_name_lookup = {r['ISO2'].lower():r['Country name'] for rid,r in country_codes.iterrows()}\n",
    "# eu_code_name_lookup['uk'] = 'United Kingdom'\n",
    "# eu_code_name_lookup['el'] = 'Greece'\n",
    "# eu_code_name_lookup['cz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a unified indicator table\n",
    "inds = pd.concat([pd.read_csv(f\"{project_dir}/data/processed/{name}_indicators.csv\") for name in\n",
    "                 ['official','web']])\n",
    "\n",
    "inds['country'] = [x.lower() for x in inds['country']]\n",
    "\n",
    "inds['variable_clean'] = [all_names[x] for x in inds['variable']]\n",
    "\n",
    "inds['country'] = [country_name_changes[x] if x in country_name_changes.keys() else x for x in inds['country']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional eurostat data for normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We downloaded this with the make_eurostat script function and processed in 4b scaling factors\n",
    "pop = pd.read_csv(f\"{project_dir}/data/processed/eurostat_demo_table.csv\")\n",
    "\n",
    "#Lower names\n",
    "pop['country'] = pop['country'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise\n",
    "\n",
    "norm_lookup = {'educ_uoe_grad02':'pop_student_age',\n",
    "               'hrst_st_nsec2':'pop_working_age',\n",
    "               'github_users':'pop_working_age',\n",
    "               'python_downloads':'pop_working_age',\n",
    "               'tech_meetups':'pop_working_age'}\n",
    "\n",
    "new_cont = []\n",
    "\n",
    "for x in set(inds['variable']):\n",
    "    \n",
    "    #If we don't need to normalise\n",
    "    if x not in norm_lookup.keys():\n",
    "        \n",
    "        #Add to the new container\n",
    "        new_cont.append(inds.loc[inds['variable']==x].reset_index(drop=True))\n",
    "        \n",
    "    else: #If we need to normalise\n",
    "        \n",
    "        rel = inds.loc[inds['variable']==x]\n",
    "        \n",
    "        #Filter population\n",
    "        #Variable to normalise with\n",
    "        var = norm_lookup[x]\n",
    "        \n",
    "        #Filter population to focus on it\n",
    "        rel_pop = pop.loc[pop['variable']==var]\n",
    "        \n",
    "        \n",
    "        #Merge with population\n",
    "        merg = pd.merge(rel,rel_pop,left_on=['country','year'],right_on=['country','year'],how='left')\n",
    "        \n",
    "        #Normalise\n",
    "        merg['value'] = merg['value']/merg['demo_pjan']\n",
    "        \n",
    "        #Add a norm append\n",
    "        merg['variable'] = x+'_norm'\n",
    "        \n",
    "        #focus on our variables\n",
    "        out = merg[['country','year','variable','value','variable_clean']]\n",
    "\n",
    "        new_cont.append(out)\n",
    "        \n",
    "ind_norm = pd.concat(new_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on the EU countries\n",
    "ind_norm_eu = ind_norm.loc[[x in eu_codes for x in ind_norm['country']]].reset_index(drop=True)\n",
    "\n",
    "ind_norm_eu['country_full'] = ind_norm_eu['country'].map(eu_codes_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add normalised names to lookup\n",
    "ind_norm_eu['variable_clean'] = [row['variable_clean'] if 'norm' not in row['variable'] else \n",
    "                                 row['variable_clean'] + \" (per capita)\" for rid,row in ind_norm_eu.iterrows()]\n",
    "\n",
    "for rid,row in ind_norm_eu.drop_duplicates('variable').iterrows():\n",
    "    \n",
    "    if row['variable'] not in all_names.keys():\n",
    "        \n",
    "        all_names[row['variable']] = row['variable_clean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_norm_eu_rec = ind_norm_eu.loc[(ind_norm_eu['year']>=2015)&((ind_norm_eu['year']<=2019))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to addd missing values for those variables without data in a year\n",
    "\n",
    "missing_dfs = []\n",
    "\n",
    "for x in set(ind_norm_eu_rec['variable_clean']):\n",
    "    \n",
    "    #Get all data in the year\n",
    "    rel = ind_norm_eu_rec.loc[ind_norm_eu_rec['variable_clean']==x]\n",
    "    \n",
    "    #What years are there?\n",
    "    years = set(rel['year'])\n",
    "    \n",
    "    #What are the missing years?\n",
    "    missing = set(np.arange(2015,2020))-years\n",
    "    \n",
    "    #For each year missing we will create a df with missing values\n",
    "    for x in missing:\n",
    "        \n",
    "        year_df = rel.loc[rel['year']==list(years)[0]]\n",
    "        year_df['year'] = x\n",
    "        year_df['value'] = np.nan\n",
    "        \n",
    "        missing_dfs.append(year_df)\n",
    "\n",
    "ind_norm_eu_rec_missing = pd.concat([ind_norm_eu_rec,pd.concat(missing_dfs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_chart(df,_vars):\n",
    "    #Missing years and missing countries\n",
    "    \n",
    "    #Focus on selected variables\n",
    "    df_ = df.loc[df['variable'].isin(_vars)]\n",
    "    \n",
    "    #Count missing values by country and year\n",
    "    miss_c = df_.groupby(['variable_clean','country_full'])['value'].apply(\n",
    "        lambda x: np.sum(x.isna()==True)).reset_index(drop=False)\n",
    "    miss_y = df_.groupby(['variable_clean','year'])['value'].apply(\n",
    "        lambda x: np.sum(x.isna()==True)).reset_index(drop=False)\n",
    "\n",
    "    #Create altair objects with variable positions\n",
    "    y_pos = alt.Y('variable_clean',sort=alt.EncodingSortField('value','mean',order='descending'))\n",
    "    x_pos = alt.X('country_full:O',sort=alt.EncodingSortField('value','sum',order='descending'))\n",
    "    x_pos_y = alt.Y('year:O')\n",
    "    \n",
    "    #Country chart\n",
    "    c = alt.Chart(miss_c).mark_point(\n",
    "        filled=True,stroke='black',strokeWidth=1).encode(\n",
    "        y=y_pos,x=x_pos,size='value',color='value').properties(width=450,height=250)\n",
    "\n",
    "    #Year chart\n",
    "    y = alt.Chart(miss_y).mark_point(\n",
    "        filled=True,stroke='black',strokeWidth=1).encode(y=alt.Y('variable_clean',axis=alt.Axis(labels=False),\n",
    "                                                                title=''),\n",
    "                                                                 x=x_pos_y,size='value',\n",
    "                                                         color=alt.Color('value',title=['Number of missing', 'values']))\n",
    "    #Concatenate variables\n",
    "    sh = alt.hconcat(c,y).resolve_scale(y='shared')\n",
    "\n",
    "    return sh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = coverage_chart(ind_norm_eu_rec_missing,set(ind_norm_eu_rec['variable']))\n",
    "\n",
    "save_altair_(cov,'fig_17_missing')\n",
    "\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate correlations between variables\n",
    "ind_2017 = ind_norm_eu.loc[ind_norm_eu['year']==2018]\n",
    "\n",
    "vs = ind_2017.pivot_table(index='country_full',columns='variable',values='value').corr()\n",
    "\n",
    "vs.index.name = 'v1'\n",
    "vs.columns.name = 'v2'\n",
    "\n",
    "vs_2 = vs.reset_index(\n",
    "    drop=False).melt(id_vars='v1')\n",
    "\n",
    "for v in ['v1','v2']:\n",
    "    vs_2[v+'_clean'] = [all_names[x] for x in vs_2[v]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_2['corr_label'] = [str(np.round(x,2)) for x in vs_2['value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos = alt.X('v1_clean:N',sort=alt.EncodingSortField('value','mean',order='descending'),title=None)\n",
    "y_pos = alt.Y('v2_clean:N',sort=alt.EncodingSortField('value','mean',order='descending'),title=None)\n",
    "\n",
    "base = alt.Chart(vs_2).mark_rect().encode(x=x_pos,y=y_pos)\n",
    "\n",
    "text = base.mark_text().encode(\n",
    "    text='corr_label',\n",
    "    color=alt.condition(\n",
    "        alt.datum.value > 0.5, \n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "col = base.encode(color='value')\n",
    "\n",
    "f = (col+text).properties(width=500,height=300)\n",
    "\n",
    "save_altair_(f,'fig_18_correlation')\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zscore(series):\n",
    "    \n",
    "    return (series - series.mean())/(series.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_2018 = ind_norm_eu.query('year == 2017').pivot_table(index='country_full',\n",
    "                                                        columns='variable_clean',\n",
    "                                                         values='value').apply(\n",
    "    lambda x: calculate_zscore(x)).reset_index(drop=False)\n",
    "\n",
    "#Remove countries with lots of missing values\n",
    "missing_values = ind_2018.set_index('country_full').isna().sum(axis=1)\n",
    "\n",
    "low_missing_countries = missing_values.index[missing_values<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_2018_long = ind_2018.loc[ind_2018['country_full'].isin(low_missing_countries)].melt(id_vars='country_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = (alt\n",
    "        .Chart(ind_2018_long)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "        y=alt.Y('country_full',title=None,sort=alt.EncodingSortField('value',op='median',order='descending')),\n",
    "        x = alt.X('variable_clean',title='Indicator',sort=alt.EncodingSortField('value',op='mean',order='descending')),\n",
    "        color=alt.Color('value',title='Z-score',scale=alt.Scale(scheme='purpleorange')))).properties(height=450)\n",
    "\n",
    "save_altair_(rank,'fig_19_ranking')\n",
    "\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse correlation between indicators and EIS\n",
    "\n",
    "#### Read EIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"https://ec.europa.eu/docsroom/documents/36062/attachments/1/translations/en/renditions/native\"\n",
    "file_2 = \"https://ec.europa.eu/docsroom/documents/41864/attachments/1/translations/en/renditions/native\"\n",
    "\n",
    "eis_df = pd.read_excel(file_2,sheet_name=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a cleaner version with nicer columns etc\n",
    "eis_ = eis_df.copy()\n",
    "\n",
    "eis_.columns = [c+'_'+str(int(x)) if pd.isnull(x)==False else c for c,x in zip(eis_.columns,eis_.iloc[0])]\n",
    "eis_.columns = [re.sub(\" \",\"_\",x.lower()) for x in eis_.columns]\n",
    "\n",
    "eis_ = eis_.iloc[2:].reset_index(drop=True).rename(columns={'unnamed:_0':'country_name',\n",
    "                                                           'unnamed:_1':'country_code'})\n",
    "\n",
    "eis_['country_code'] = eis_['country_code'].apply(lambda x: x.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eis_2019 = eis_.iloc[:,:3]\n",
    "\n",
    "#eis_2018['year'] = 2018\n",
    "\n",
    "eis_2019.rename(columns={'summary_innovation_index_2019':'eis_2019'},inplace=True)\n",
    "\n",
    "eis_2019['eis_2019'] = pd.to_numeric(eis_2019['eis_2019'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allocate countries to quartiles (ranking)\n",
    "\n",
    "eis_2019['position'] = pd.qcut(eis_2019['eis_2019'],q=np.arange(0,1.1,0.2),labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We focus on our variables of interest\n",
    "ind_eis = pd.merge(ind_norm_eu,eis_2019,left_on=['country'],right_on=['country_code'],\n",
    "                   how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For our variables we want to keep similar years\n",
    "\n",
    "vars_2018 = ['hrst_st_nsec2_norm','educ_uoe_grad02_norm','tech_meetups_norm','github_users_norm']\n",
    "\n",
    "year_var = {v:2019 if v not in vars_2018 else 2018 for v in set(ind_eis['variable'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_eis['year_match'] = [row['year']==year_var[row['variable']] for _id,row in ind_eis.iterrows()]\n",
    "\n",
    "ind_eis_sh = ind_eis.loc[ind_eis['year_match']==True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What variables do we keep?\n",
    "key_vars = ['hrst_st_nsec2_norm','educ_uoe_grad02_norm','isoc_sk_dskl_i','github_users_norm','tech_meetups_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov = coverage_chart(ind_norm_eu_rec_missing,key_vars)\n",
    "\n",
    "# save_altair_(cov,\"selected_coverage\")\n",
    "\n",
    "# cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correlation_chart(df,indicators):\n",
    "    '''Creates a barchart with selected indicators\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    eis_corr = df.pivot_table(index='country',columns='variable',values='value')[indicators].corrwith(\n",
    "    eis_2019.set_index('country_code')['eis_2019']).reset_index(name='correlation')\n",
    "\n",
    "    eis_corr['variable_clean'] = eis_corr['variable'].map(all_names)\n",
    "\n",
    "    corr_ch = alt.Chart(eis_corr).mark_bar().encode(\n",
    "        y=alt.Y('variable_clean',\n",
    "                title='Variable',sort=alt.EncodingSortField('correlation',order='descending')),\n",
    "        x=alt.X('correlation',title=['Correlation coefficient','with EIS-2019'])).properties(height=150,width=200)\n",
    "\n",
    "    #corr_ch.save(f\"{fig_path}/correlation_chart.png\",webdriver=driver,method='selenium',scale_factor=3)\n",
    "    return(corr_ch)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = make_correlation_chart(ind_eis_sh,key_vars).properties(width=300,height=100)\n",
    "\n",
    "save_altair_(corr,'fig_20_correlation_w_eis')\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_eis_link_chart(df,variable):\n",
    "    \n",
    "#     #Subset the df to focus on the variable of interest\n",
    "#     df_sub = df.loc[df['variable']==variable].reset_index(drop=False).dropna()\n",
    "    \n",
    "#     #This is a lookup to relabel the outputs of our model\n",
    "#     ind_label_lookup = df_sub.to_dict(orient='index')\n",
    "\n",
    "#     #We want to calculate the residuals of the model that regresses eis on the variable of interest\n",
    "#     mod = sm.OLS(df_sub['value'],sm.add_constant(df_sub['eis_2018']),missing='drop')\n",
    "#     outp = mod.fit()\n",
    "    \n",
    "#     #Extract the residuals and sort them\n",
    "#     outp = outp.resid.sort_values().reset_index(name='residual')\n",
    "#     outp['country'] = [ind_label_lookup[x]['country_full'] for x in outp['index']]\n",
    "\n",
    "#     #Merge residuals table with main table. We want them in the same table to link variables in the visualisation below\n",
    "#     df_sub_2 = df_sub.merge(outp[['country_full','residual']],left_on='country_full',right_on='country_full')\n",
    "    \n",
    "#     #Plotting\n",
    "#     #Create selection object\n",
    "#     sel = alt.selection_interval()\n",
    "    \n",
    "#     #Create selection object\n",
    "#     col = alt.condition(sel,'position:N',alt.value('lightgrey'))\n",
    "    \n",
    "#     #Create the scatter\n",
    "#     scatter = (alt.Chart(df_sub_2)\n",
    "#                .mark_point(filled=True,size=40)\n",
    "#                .encode(y='eis_2018',x='value',tooltip=['country_full'],\n",
    "#                        color=col))\n",
    "    \n",
    "#     #Create the regression line\n",
    "#     reg_line = scatter.transform_regression('value','eis_2018',method='linear').mark_line(strokeDash=[2,2])\n",
    "    \n",
    "#     #Create the scatter + line\n",
    "#     scatter_line = ((scatter + reg_line)\n",
    "#                     .properties(height=150,width=150,title=all_names[variable][:30]+'...')\n",
    "#                     .add_selection(sel))\n",
    "\n",
    "#     #Add a barchart with residuals\n",
    "#     res_bar = (alt.Chart(df_sub_2)\n",
    "#                .mark_bar()\n",
    "#                .encode(\n",
    "#                    y=alt.Y('country_full',sort=alt.SortByEncoding('x',order='descending'),axis=alt.Axis(grid=True)),\n",
    "#                    x='residual',\n",
    "#                    color=col,\n",
    "#                    tooltip=['country_full'])).properties(height=400,width=150).add_selection(sel)\n",
    "\n",
    "#     comp = alt.vconcat(scatter_line,res_bar)\n",
    "#     return([df_sub_2,comp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eis_link_chart_2(df,variable):\n",
    "    '''Version of the eis_link chart but visualising ranking changes instead of residuals\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Subset the df to focus on the variable of interest\n",
    "    df_sub = df.loc[df['variable']==variable].reset_index(drop=False).dropna()\n",
    "    \n",
    "    #This is a lookup to relabel the outputs of our model\n",
    "    ind_label_lookup = df_sub.to_dict(orient='index')\n",
    "    \n",
    "    rank_changes = df_sub.set_index('country_full').assign(\n",
    "            ranking_difference = lambda x: x['value'].rank()-x['eis_2019'].rank())[\n",
    "            'ranking_difference'].reset_index(drop=False)\n",
    "\n",
    "    #Merge residuals table with main table. We want them in the same table to link variables in the visualisation below\n",
    "    df_sub_2 = df_sub.merge(rank_changes[['country_full','ranking_difference']],left_on='country_full',\n",
    "                            right_on='country_full')\n",
    "    \n",
    "    #Plotting\n",
    "    #Create selection object\n",
    "    sel = alt.selection_interval()\n",
    "    \n",
    "    #Create selection object\n",
    "    col = alt.condition(sel,alt.Color('position:N',title='Quintile'),\n",
    "                                      alt.value('lightgrey'))\n",
    "    \n",
    "    col_2 = alt.condition(sel,alt.Color('position:N',legend=None),\n",
    "                                      alt.value('lightgrey'))\n",
    "    \n",
    "    \n",
    "    #Create the scatter\n",
    "    scatter = (alt.Chart(df_sub_2)\n",
    "               .mark_point(filled=True,size=40)\n",
    "               .encode(y=alt.Y('eis_2019',title='EIS 2019'),\n",
    "                       x='value',tooltip=['country'],\n",
    "                       color=col_2))\n",
    "    \n",
    "    #Create the regression line\n",
    "    reg_line = scatter.transform_regression('value','eis_2019',method='linear').mark_line(\n",
    "        strokeDash=[2,2])\n",
    "    \n",
    "    #Create the scatter + line\n",
    "    scatter_line = ((scatter + reg_line)\n",
    "                    .properties(height=150,width=150,title=all_names[variable][:30]+'...')\n",
    "                    .add_selection(sel)).resolve_scale(color='independent')\n",
    "\n",
    "    #Add a barchart with residuals\n",
    "    res_bar = (alt.Chart(df_sub_2)\n",
    "               .mark_bar()\n",
    "               .encode(\n",
    "                   y=alt.Y('country_full',title='Country',\n",
    "                           sort=alt.SortByEncoding('x',order='descending'),axis=alt.Axis(grid=True)),\n",
    "                   x=alt.X('ranking_difference',title=['Change in ranking','EIS 2019 - indicator']),\n",
    "                   color=col,\n",
    "                   tooltip=['country_full'])).properties(height=400,width=150).add_selection(sel)\n",
    "\n",
    "    comp = alt.vconcat(scatter_line,res_bar)\n",
    "    return([df_sub_2,comp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiple_link_charts(df,variables):\n",
    "    '''Creates concatenated charts \n",
    "    \n",
    "    '''\n",
    "    outs = [make_eis_link_chart_2(df,v) for v in variables]\n",
    "\n",
    "    scatter_charts = alt.hconcat(*[x[1] for x in outs]).resolve_scale(x='shared')\n",
    "\n",
    "    return scatter_charts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_charts = make_multiple_link_charts(ind_eis_sh,key_vars)\n",
    "save_altair_(scatter_charts,\"scatters\")\n",
    "\n",
    "scatter_charts.save(f\"{save_dir}/indicator_eis_comparison.html\")\n",
    "save_altair_(scatter_charts,'fig_21_scatters')\n",
    "\n",
    "scatter_charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_change_plot(df,indicators):\n",
    "    '''Creates a plot about country ranking differences according to various indicators\n",
    "    \n",
    "    '''\n",
    "\n",
    "    rank_changes = df.groupby('variable').apply(\n",
    "        lambda x: x.set_index('country_full').assign(\n",
    "            ranking_difference = lambda x: x['value'].rank()-x['eis_2019'].rank())[\n",
    "            ['position','ranking_difference']]).reset_index(drop=False)\n",
    "    \n",
    "    #Create selection object\n",
    "    sel = alt.selection_interval(encodings=['x'])\n",
    "    \n",
    "    #Create color object\n",
    "    col = alt.condition(sel,alt.Color('position:N',title='Quintile'),\n",
    "                                      alt.value('lightgrey'))\n",
    "\n",
    "    rank_changes_selected = rank_changes.loc[rank_changes['variable'].isin(indicators)]\n",
    "\n",
    "    rank_changes_selected['variable_clean'] = rank_changes_selected['variable'].map(all_names)\n",
    "    \n",
    "    rank_chart = (alt.Chart(rank_changes_selected)\n",
    "                  .mark_bar()\n",
    "                  .encode(\n",
    "                      x=alt.X('country_full',sort=alt.EncodingSortField('position',order='descending'),\n",
    "                             title=None),\n",
    "                      y=alt.Y('ranking_difference',title=['Ranking','difference']),\n",
    "                      #color='position:N',\n",
    "                      color=col,\n",
    "                      tooltip=['country_full'],\n",
    "                      row=alt.Row('variable_clean',header=alt.Header(labelOrient='top'),\n",
    "                                  sort=[all_names[x] for x in key_vars]))\n",
    "                  .properties(height=80,width=500).configure_axisX(grid=True)).add_selection(sel)\n",
    "    \n",
    "    return(rank_chart)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ch = rank_change_plot(ind_eis_sh,key_vars)\n",
    "\n",
    "save_altair_(rank_ch,\"ranking_change\")\n",
    "\n",
    "rank_ch.save(f\"{fig_path}/indicator_rank_differences.html\")\n",
    "save_altair_(rank_ch,'fig_22_ranking_change')\n",
    "\n",
    "rank_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_vars_2 = ['isoc_ski_itemp','isoc_ci_ifp_iu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_correlation_chart(ind_eis_sh,key_vars_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_multiple_link_charts(ind_eis_sh,key_vars_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_change_plot(ind_eis_sh,key_vars_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some extra analysis for the internal workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in key_vars:\n",
    "    print(x)\n",
    "    print(all_names[x])\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in key_vars:\n",
    "    print(all_names[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
